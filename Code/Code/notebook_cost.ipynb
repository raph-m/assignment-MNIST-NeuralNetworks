{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from read_dataset import read_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from displayData import displayData\n",
    "from randInitializeWeights import randInitializeWeights\n",
    "from unroll_params import unroll_params\n",
    "from roll_params import roll_params\n",
    "import scipy.optimize as opt\n",
    "from predict import predict\n",
    "from backwards import backwards\n",
    "from checkNNGradients import checkNNGradients\n",
    "from sigmoid import sigmoid\n",
    "from sigmoidGradient import sigmoidGradient\n",
    "from debugInializeWeights import debugInitializeWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(nn_weights, layers, X, y, num_labels, lambd):\n",
    "    # Computes the cost function of the neural network.\n",
    "    # nn_weights: Neural network parameters (vector)\n",
    "    # layers: a list with the number of units per layer.\n",
    "    # X: a matrix where every row is a training example for a handwritten digit image\n",
    "    # y: a vector with the labels of each instance\n",
    "    # num_labels: the number of units in the output layer\n",
    "    # lambd: regularization factor\n",
    "    \n",
    "    # Setup some useful variables\n",
    "    m = X.shape[0]\n",
    "    num_layers = len(layers)\n",
    "\n",
    "    # Unroll Params\n",
    "    Theta = roll_params(nn_weights, layers)\n",
    "\n",
    "    # ================================ TODO ================================\n",
    "    # The vector y passed into the function is a vector of labels\n",
    "    # containing values from 1..K. You need to map this vector into a \n",
    "    # binary vector of 1's and 0's to be used with the neural network\n",
    "    # cost function.\n",
    "    yv = np.zeros((num_labels, m))\n",
    "    for i in range(len(y)):\n",
    "        yv[int(y[i])] = 1  # TODO: the int conversion is maybe not useful\n",
    "    yv = np.transpose(yv)\n",
    "\n",
    "    # ================================ TODO ================================\n",
    "    # In this point calculate the cost of the neural network (feedforward)\n",
    "    x = np.copy(X)\n",
    "\n",
    "    for i in range(num_layers - 1):\n",
    "        s = np.shape(Theta[i])\n",
    "        theta = Theta[i][:, 1:s[1]]\n",
    "        x = np.dot(theta, np.transpose(x))\n",
    "        for j in range(m):\n",
    "            x[:, j] += Theta[i][:, 0]\n",
    "        x = np.transpose(sigmoid(x))\n",
    "\n",
    "    cost = (yv * np.log(x) - (1 - yv) * np.log(1 - x)) / m\n",
    "    cost = -np.sum(cost)\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        cost += lambd * np.sum(Theta[i] ** 2) / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNNCost(lambd):\n",
    "\n",
    "    input_layer_size  = 3;\n",
    "    hidden_layer_size = 5;\n",
    "    num_labels = 3;\n",
    "    m          = 5;\n",
    "    layers     = [3, 5, 3]\n",
    "    \n",
    "    Theta = [] \n",
    "    Theta.append(debugInitializeWeights(hidden_layer_size, input_layer_size))\n",
    "    Theta.append(debugInitializeWeights(num_labels, hidden_layer_size))\n",
    "    nn_params = unroll_params(Theta)\n",
    "    \n",
    "    X = debugInitializeWeights(m, input_layer_size - 1)\n",
    "    y = np.remainder(np.arange(m)+1, num_labels)\n",
    " \n",
    "    cost = costFunction(nn_params, layers, X, y, num_labels, lambd)\n",
    "    print('Cost: ' + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 2.03232082178\n"
     ]
    }
   ],
   "source": [
    "lambd = 0.0\n",
    "checkNNCost(lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 2.09153578476\n"
     ]
    }
   ],
   "source": [
    "lambd = 3.0\n",
    "checkNNCost(lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}